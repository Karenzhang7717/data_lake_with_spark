{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7196a050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c729fd2f895c4692b2a353e34cb9f115",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>0</td><td>application_1640973840716_0001</td><td>spark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-40-53.ec2.internal:20888/proxy/application_1640973840716_0001/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-39-83.ec2.internal:8042/node/containerlogs/container_1640973840716_0001_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res1: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@563b963c\n"
     ]
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dc1b966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c3a2793008b434db1387f11ccbfdca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import configparser\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col, monotonically_increasing_id\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format\n",
    "from pyspark.sql.types import StructType as R, StructField as Fld, DoubleType as Dbl, StringType as Str, IntegerType as Int, DateType as Date\n",
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d7eba13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bfa2f9c281d41c59b1d750565ffe99f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_path = \"s3://s3-bucket-kzzz777/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3826d128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb55b969d62b434fa1d6926e1f0a7caf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get filepath to song data file\n",
    "songSchema = R([\n",
    "Fld(\"num_songs\",Int()),\n",
    "Fld(\"artist_id\",Str()),\n",
    "Fld(\"artist_latitude\",Dbl()),\n",
    "Fld(\"artist_longitude\",Dbl()),\n",
    "Fld(\"artist_location\",Str()),\n",
    "Fld(\"artist_name\",Str()),\n",
    "Fld(\"title\",Str()),\n",
    "Fld(\"duration\",Dbl()),\n",
    "Fld(\"year\",Int()),\n",
    "\n",
    "])\n",
    "\n",
    "# read song data file, create a staging_songs table first\n",
    "staging_songs = spark.read.json(\"s3a://udacity-dend/song_data/A/A/*/*.json\",schema=songSchema)\n",
    "staging_songs = staging_songs.withColumn('song_id', monotonically_increasing_id())\n",
    "\n",
    "staging_songs.registerTempTable(\"staging_songs\")\n",
    "\n",
    "# dedup songs data and create songs table\n",
    "songs_table = spark.sql(\"\"\"SELECT DISTINCT song_id, title, artist_id, year, duration \n",
    "                            FROM \n",
    "                                (SELECT \n",
    "                                    song_id, title, artist_id, year, duration, ROW_NUMBER() OVER(PARTITION BY song_id ORDER BY title desc) AS sequence \n",
    "                                FROM \n",
    "                                    staging_songs) AS ss\n",
    "                                 WHERE sequence =1   \n",
    "                        \"\"\")\n",
    "\n",
    "# write songs table to parquet files partitioned by year and artist\n",
    "songs_table.write.mode(\"overwrite\").partitionBy(\"year\", \"artist_id\").parquet(output_path+\"songs_table\")\n",
    "\n",
    "#dedup artists data and create artists table\n",
    "artists_table = spark.sql(\"\"\"SELECT DISTINCT artist_id, artist, location, latitude, longitude\n",
    "                                FROM \n",
    "                                    (SELECT \n",
    "                                        artist_id, artist_name as artist, artist_location as location, artist_latitude as latitude, artist_longitude as longitude,\n",
    "                                        ROW_NUMBER() OVER (PARTITION BY artist_id ORDER BY artist_name desc) AS sequence\n",
    "                                        FROM staging_songs) AS ss\n",
    "                                        WHERE sequence=1\n",
    "                        \"\"\")\n",
    "\n",
    "# write artists table to parquet files\n",
    "artists_table.write.mode(\"overwrite\").parquet(output_path+\"artists_table/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad1bf24d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64f97e11a7574a079a698a01dec03632",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read log data file\n",
    "staging_events= spark.read.json(\"s3a://udacity-dend/log_data/*/*/*.json\")\n",
    "\n",
    "# filter by actions for song plays\n",
    "staging_events = staging_events.filter(staging_events.page == \"NextSong\")\n",
    "\n",
    "# create songplay_id column for staging_events\n",
    "staging_events = staging_events.withColumn('songplay_id', monotonically_increasing_id())\n",
    "\n",
    "# create timestamp column from original timestamp column\n",
    "get_datetime = udf(lambda x: datetime.fromtimestamp((x / 1000)), types.TimestampType())\n",
    "staging_events = staging_events.withColumn(\"timestamp\", get_datetime(\"ts\"))\n",
    "\n",
    "# create a TempTable for sql queries\n",
    "staging_events.registerTempTable(\"staging_events\")\n",
    "\n",
    "#dedup users data and create users table\n",
    "users_table = spark.sql(\"\"\"SELECT DISTINCT user_id, first_name, last_name, gender, level\n",
    "                            FROM \n",
    "                                (SELECT \n",
    "                                        userId as user_id, firstName as first_name, lastName as last_name, gender, level,\n",
    "                                        ROW_NUMBER() OVER (PARTITION BY userId ORDER BY lastName) AS sequence\n",
    "                                        FROM staging_events) AS se\n",
    "                                        WHERE sequence =1 AND user_id IS NOT NULL\n",
    "                            \"\"\")\n",
    "\n",
    "# write users table to parquet files\n",
    "users_table.write.mode(\"overwrite\").parquet(output_path+\"users_table/\")\n",
    "\n",
    "# dedup time data and create time table\n",
    "time_table = spark.sql(\"\"\"SELECT DISTINCT timestamp FROM staging_events WHERE timestamp IS NOT NULL\n",
    "                        \"\"\")\n",
    "\n",
    "# extract columns from timestamp\n",
    "time_table = time_table.select(\n",
    "                col('timestamp').alias('start_time'),\n",
    "                hour('timestamp').alias('hour'),\n",
    "                dayofmonth('timestamp').alias('day'),\n",
    "                weekofyear('timestamp').alias('week'),\n",
    "                month('timestamp').alias('month'),\n",
    "                year('timestamp').alias('year'))\n",
    "\n",
    "# write time table to parquet files partitioned by year and month\n",
    "time_table.write.mode(\"overwrite\").partitionBy(\"year\", \"month\").parquet(output_path + \"time_table/\")\n",
    "\n",
    "# drop Tempviews for songs and artists in case it existed already\n",
    "spark.catalog.dropTempView(\"songs\")\n",
    "spark.catalog.dropTempView(\"artists\")\n",
    "\n",
    "# read in song data to use for songplays table and create table\n",
    "song_df = spark.read.parquet(output_path + 'songs_table/')\n",
    "song_df.createTempView(\"songs\")\n",
    "\n",
    "# read in artist data and create table\n",
    "artist_df = spark.read.parquet(output_path + \"artists_table/\")\n",
    "artist_df.createTempView(\"artists\")\n",
    "\n",
    "# extract columns from joined song and log datasets to create songplays table; include year and month to allow parquet partitioning\n",
    "songplays_table = spark.sql(\"\"\"\n",
    "    SELECT DISTINCT\n",
    "        se.songplay_id,\n",
    "        se.timestamp as start_time,\n",
    "        se.userId as user_id,\n",
    "        se.level,\n",
    "        tmp.song_id,\n",
    "        tmp.artist_id,\n",
    "        se.sessionId as session_id,\n",
    "        se.location,\n",
    "        se.userAgent as user_agent,\n",
    "        year(se.timestamp) as year,\n",
    "        month(se.timestamp) as month\n",
    "    FROM staging_events se\n",
    "    LEFT JOIN (SELECT \n",
    "        s.song_id, a.artist_id, s.title, s.duration, a.artist FROM songs s\n",
    "        INNER JOIN artists a ON s.artist_id = a.artist_id) AS tmp\n",
    "    ON\n",
    "        se.song = tmp.title AND\n",
    "        se.artist = tmp.artist\n",
    "    WHERE se.page='NextSong'\n",
    "\"\"\")\n",
    "\n",
    "# write songplays table to parquet files partitioned by year and month\n",
    "songplays_table.write.partitionBy('year','month').mode(\"overwrite\").parquet(output_path + 'songplays_table/')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a25e36a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1f32198fb0e49dba2ab27586adbc720",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "songplay_df = spark.read.parquet(output_path + 'songplays_table/')\n",
    "songplay_df.createTempView(\"songplays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "701704e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cd9834fbe8d443e9e76e9b22ec70c84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+-------+-----+-----------+------------------+----------+--------------------+--------------------+----+-----+\n",
      "|songplay_id|          start_time|user_id|level|    song_id|         artist_id|session_id|            location|          user_agent|year|month|\n",
      "+-----------+--------------------+-------+-----+-----------+------------------+----------+--------------------+--------------------+----+-----+\n",
      "|         62|2018-11-15 10:56:...|     80| paid|       null|              null|       611|Portland-South Po...|\"Mozilla/5.0 (Mac...|2018|   11|\n",
      "|34359738503|2018-11-08 14:54:...|     29| paid|       null|              null|       372|Atlanta-Sandy Spr...|\"Mozilla/5.0 (Mac...|2018|   11|\n",
      "| 8589934822|2018-11-05 16:02:...|     73| paid|       null|              null|       255|Tampa-St. Petersb...|\"Mozilla/5.0 (Mac...|2018|   11|\n",
      "|        978|2018-11-14 05:45:...|     80| paid|       null|              null|       548|Portland-South Po...|\"Mozilla/5.0 (Mac...|2018|   11|\n",
      "|       1374|2018-11-28 09:43:...|     82| paid|       null|              null|       140|Atlanta-Sandy Spr...|\"Mozilla/5.0 (Mac...|2018|   11|\n",
      "|        990|2018-11-14 06:15:...|     80| paid|       null|              null|       548|Portland-South Po...|\"Mozilla/5.0 (Mac...|2018|   11|\n",
      "|       1220|2018-11-14 15:47:...|     80| paid|       null|              null|       574|Portland-South Po...|\"Mozilla/5.0 (Mac...|2018|   11|\n",
      "| 8589934626|2018-11-05 05:51:...|     57| free|       null|              null|        56|San Antonio-New B...|\"Mozilla/5.0 (Mac...|2018|   11|\n",
      "|       1423|2018-11-28 12:18:...|     97| paid|       null|              null|       944|Lansing-East Lans...|\"Mozilla/5.0 (X11...|2018|   11|\n",
      "|25769804476|2018-11-09 20:11:...|     49| free|       null|              null|       405|San Francisco-Oak...|Mozilla/5.0 (Wind...|2018|   11|\n",
      "|17179870205|2018-11-19 05:40:...|     24| paid|       null|              null|       672|Lake Havasu City-...|\"Mozilla/5.0 (Win...|2018|   11|\n",
      "|17179869356|2018-11-20 14:14:...|     44| paid|       null|              null|       639|Waterloo-Cedar Fa...|Mozilla/5.0 (Maci...|2018|   11|\n",
      "|42949673373|2018-11-18 19:23:...|     77| free|       null|              null|       656|Dallas-Fort Worth...|\"Mozilla/5.0 (Win...|2018|   11|\n",
      "| 8589935228|2018-11-13 21:20:...|     29| paid|       null|              null|       556|Atlanta-Sandy Spr...|\"Mozilla/5.0 (Mac...|2018|   11|\n",
      "|17179870259|2018-11-19 09:09:...|     24| paid|       null|              null|       672|Lake Havasu City-...|\"Mozilla/5.0 (Win...|2018|   11|\n",
      "|        152|2018-11-15 14:17:...|     97| paid|       null|              null|       605|Lansing-East Lans...|\"Mozilla/5.0 (X11...|2018|   11|\n",
      "|51539607866|2018-11-11 16:01:...|     62| free|       null|              null|       218|Houston-The Woodl...|\"Mozilla/5.0 (Mac...|2018|   11|\n",
      "| 8589934898|2018-11-05 17:49:...|     73| paid|85899345932|ARC0IOF1187FB3F6E6|       255|Tampa-St. Petersb...|\"Mozilla/5.0 (Mac...|2018|   11|\n",
      "|        596|2018-11-21 06:46:...|     97| paid|       null|              null|       797|Lansing-East Lans...|\"Mozilla/5.0 (X11...|2018|   11|\n",
      "| 8589934833|2018-11-05 16:18:...|     97| paid|       null|              null|       147|Lansing-East Lans...|\"Mozilla/5.0 (X11...|2018|   11|\n",
      "+-----------+--------------------+-------+-----+-----------+------------------+----------+--------------------+--------------------+----+-----+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "songplay_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d79abfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
